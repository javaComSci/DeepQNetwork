{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import random, sample\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from collections import deque\n",
    "%run MazeEnv.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        # hyperparameters\n",
    "        self.episodes = 500\n",
    "        self.time_allowed_in_game = 150\n",
    "        self.epsilon = 1\n",
    "        self.min_epsilon = 0.01\n",
    "        self.epsilon_multiplier = 0.95\n",
    "        self.discount_rate = 0.9\n",
    "\n",
    "        # create 2 models here - one for use with the predictions and the other to train on\n",
    "        # the target model will be set to the trained model after a specfic num of iterations\n",
    "        self.model = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "        # both models must start with the same weights\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "        # create the list for the replay memory\n",
    "        self.replay_memory = deque(maxlen=1028)\n",
    "        \n",
    "        # keep track of how often the target_weights = normal_weights\n",
    "        self.t_target_current = 0\n",
    "        self.t_target_threshold = 256\n",
    "        # keep track of how often the to get from minibatch and train\n",
    "        self.t_train_current = 0\n",
    "        self.t_train_threshold = 128\n",
    "        # mini batch to train on\n",
    "        self.mini_batch_size = 64\n",
    "        \n",
    "    \n",
    "    # create the model structure to be used\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # inputs will be the x and y coordinates of the maze - 2 input\n",
    "        model.add(Dense(3, input_dim = 2, activation = \"relu\"))\n",
    "        model.add(Dense(4, activation = \"linear\"))\n",
    "        \n",
    "        # the mse loss works best in dnq\n",
    "        model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
    "        return model\n",
    "\n",
    "    \n",
    "    # choose an action to perform in the game\n",
    "    def select_action(self, state):\n",
    "        r = random()\n",
    "        # choose a random action\n",
    "        if r < self.epsilon:\n",
    "            # this is coming from the maze file\n",
    "            return select_move_from_num(r)\n",
    "        else:\n",
    "            x = state[0]\n",
    "            y = state[1]\n",
    "            inputs = np.array([x, y]).reshape((1, 2))\n",
    "            move_prediction = np.array(self.model.predict(inputs)[0])\n",
    "            prediction = np.argmax(move_prediction)\n",
    "            return prediction\n",
    "    \n",
    "    \n",
    "    # train the model\n",
    "    def train(self):\n",
    "        print(\"TRAINING\")\n",
    "        # training the model based on the minibatch - check if enough to do the training\n",
    "        if len(self.replay_memory) < self.mini_batch_size:\n",
    "            return\n",
    "        \n",
    "        # get a sample of the replay memory with the minibatch\n",
    "        mini_batch = sample(self.replay_memory, self.mini_batch_size)\n",
    "        \n",
    "        # use the target values for training the model\n",
    "        target_y = []\n",
    "        x = []\n",
    "        \n",
    "        # go through each of the transitions for gradient descent\n",
    "        for i, (old_state, action_direction, reward, new_state, done) in enumerate(mini_batch):\n",
    "            actual = reward\n",
    "            if done == False:\n",
    "                inputs = np.array(new_state).reshape((1, 2))\n",
    "                move_prediction = np.array(self.target_model.predict(inputs)[0])\n",
    "                next_state_q_val = max(move_prediction)\n",
    "                actual = reward + (self.discount_rate * next_state_q_val)\n",
    "            \n",
    "            target_y.append(actual)\n",
    "            x.append(list(old_state))\n",
    "            \n",
    "        target_y = np.array(target_y).reshape((len(target_y), 1))\n",
    "        x = np.array(x).reshape((len(x), 2))\n",
    "        self.model.fit(x, target_y)\n",
    "        \n",
    "        \n",
    "    # run the game multiple times across the env\n",
    "    def run_game(self):\n",
    "        for i in range(self.episodes):\n",
    "            print(f\"EPISODE {i}\")\n",
    "            env = Environment()\n",
    "            \n",
    "            for j in range(self.time_allowed_in_game):\n",
    "                # get the values for the transition tuple to add to replay memory\n",
    "                old_state = (env.current_point_x, env.current_point_y)\n",
    "                action_direction = self.select_action(old_state)\n",
    "                env.move(action_direction)\n",
    "                new_state = (env.current_point_x, env.current_point_y)\n",
    "                done = env.is_done()\n",
    "                reward = env.get_reward()\n",
    "#                 print(old_state, action_direction, new_state, reward)\n",
    "                self.replay_memory.append((old_state, action_direction, reward, new_state, done))\n",
    "                \n",
    "                self.t_train_current += 1\n",
    "                self.t_target_current += 1\n",
    "                \n",
    "                if self.t_train_current % self.t_train_threshold == 0:\n",
    "                    self.train()\n",
    "                \n",
    "                # update the target model with the weight of the trained model\n",
    "                if self.t_target_current % self.t_target_threshold == 0:\n",
    "                    self.target_model.set_weights(self.model.get_weights())\n",
    "                \n",
    "                # break out of loop since it is completed - no longer wait on timesteps\n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            # modify the epsilon value after each episode\n",
    "            # encourage exploration at the beginning then exploitation\n",
    "            self.epsilon = max(self.epsilon * self.epsilon_multiplier, self.min_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE 0\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 988us/step - loss: 54.9512\n",
      "EPISODE 1\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 974us/step - loss: 35.9967\n",
      "EPISODE 2\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.4902\n",
      "EPISODE 3\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 916us/step - loss: 23.9365\n",
      "EPISODE 4\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.1211\n",
      "EPISODE 5\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 970us/step - loss: 13.8462\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.1521\n",
      "EPISODE 6\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4245\n",
      "EPISODE 7\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.5575\n",
      "EPISODE 8\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 908us/step - loss: 3.5798\n",
      "EPISODE 9\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 792us/step - loss: 3.8813\n",
      "EPISODE 10\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8364\n",
      "EPISODE 11\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9671\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0875\n",
      "EPISODE 12\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9275\n",
      "EPISODE 13\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 993us/step - loss: 2.9292\n",
      "EPISODE 14\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2961\n",
      "EPISODE 15\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 960us/step - loss: 1.9392\n",
      "EPISODE 16\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 966us/step - loss: 1.9317\n",
      "EPISODE 17\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 908us/step - loss: 2.3735\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7845\n",
      "EPISODE 18\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7109\n",
      "EPISODE 19\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.8726\n",
      "EPISODE 20\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 961us/step - loss: 3.1052\n",
      "EPISODE 21\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 770us/step - loss: 3.0148\n",
      "EPISODE 22\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 930us/step - loss: 2.9284\n",
      "EPISODE 23\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 999us/step - loss: 2.4493\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1658\n",
      "EPISODE 24\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 949us/step - loss: 1.5601\n",
      "EPISODE 25\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 976us/step - loss: 2.2528\n",
      "EPISODE 26\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 950us/step - loss: 1.3342\n",
      "EPISODE 27\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 947us/step - loss: 1.0826\n",
      "EPISODE 28\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 972us/step - loss: 0.8794\n",
      "EPISODE 29\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8370\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 990us/step - loss: 0.8176\n",
      "EPISODE 30\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 994us/step - loss: 0.8269\n",
      "EPISODE 31\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 819us/step - loss: 0.8141\n",
      "EPISODE 32\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 942us/step - loss: 0.8027\n",
      "EPISODE 33\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.8076\n",
      "EPISODE 34\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7964\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7933\n",
      "EPISODE 35\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7906\n",
      "EPISODE 36\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 965us/step - loss: 0.7878\n",
      "EPISODE 37\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 992us/step - loss: 0.7852\n",
      "EPISODE 38\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7827\n",
      "EPISODE 39\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 921us/step - loss: 0.7883\n",
      "EPISODE 40\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.7860\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7750\n",
      "EPISODE 41\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7727\n",
      "EPISODE 42\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 921us/step - loss: 0.7700\n",
      "EPISODE 43\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 962us/step - loss: 0.7677\n",
      "EPISODE 44\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 951us/step - loss: 0.7816\n",
      "EPISODE 45\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 941us/step - loss: 0.7628\n",
      "EPISODE 46\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.7601\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7743\n",
      "EPISODE 47\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 859us/step - loss: 0.7634\n",
      "EPISODE 48\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7528\n",
      "EPISODE 49\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7501\n",
      "EPISODE 50\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 995us/step - loss: 0.7477\n",
      "EPISODE 51\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 847us/step - loss: 0.7613\n",
      "EPISODE 52\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 914us/step - loss: 0.7426\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7399\n",
      "EPISODE 53\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 952us/step - loss: 0.7457\n",
      "EPISODE 54\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 986us/step - loss: 0.7348\n",
      "EPISODE 55\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 923us/step - loss: 0.7324\n",
      "EPISODE 56\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7297\n",
      "EPISODE 57\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7274\n",
      "EPISODE 58\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7326\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7223\n",
      "EPISODE 59\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 924us/step - loss: 0.7275\n",
      "EPISODE 60\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7172\n",
      "EPISODE 61\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 948us/step - loss: 0.7303\n",
      "EPISODE 62\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 760us/step - loss: 0.7120\n",
      "EPISODE 63\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7092\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 946us/step - loss: 0.7068\n",
      "EPISODE 64\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 992us/step - loss: 0.7039\n",
      "EPISODE 65\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7016\n",
      "EPISODE 66\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6988\n",
      "EPISODE 67\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 899us/step - loss: 0.6965\n",
      "EPISODE 68\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 914us/step - loss: 0.7016\n",
      "EPISODE 69\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 955us/step - loss: 0.7071\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 834us/step - loss: 0.6885\n",
      "EPISODE 70\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 981us/step - loss: 0.6861\n",
      "EPISODE 71\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 880us/step - loss: 0.6989\n",
      "EPISODE 72\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 977us/step - loss: 0.6808\n",
      "EPISODE 73\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 965us/step - loss: 0.6779\n",
      "EPISODE 74\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6755\n",
      "EPISODE 75\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6726\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6703\n",
      "EPISODE 76\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 989us/step - loss: 0.6674\n",
      "EPISODE 77\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 906us/step - loss: 0.6728\n",
      "EPISODE 78\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 973us/step - loss: 0.6700\n",
      "EPISODE 79\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 922us/step - loss: 0.6676\n",
      "EPISODE 80\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 890us/step - loss: 0.6724\n",
      "EPISODE 81\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6545\n",
      "TRAINING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 913us/step - loss: 0.6516\n",
      "EPISODE 82\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 877us/step - loss: 0.6491\n",
      "EPISODE 83\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 962us/step - loss: 0.6462\n",
      "EPISODE 84\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 867us/step - loss: 0.6515\n",
      "EPISODE 85\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6486\n",
      "EPISODE 86\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 937us/step - loss: 0.6386\n",
      "EPISODE 87\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 901us/step - loss: 0.6508\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 913us/step - loss: 0.6333\n",
      "EPISODE 88\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 937us/step - loss: 0.6304\n",
      "EPISODE 89\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6279\n",
      "EPISODE 90\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 975us/step - loss: 0.6251\n",
      "EPISODE 91\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6227\n",
      "EPISODE 92\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 968us/step - loss: 0.6199\n",
      "EPISODE 93\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 873us/step - loss: 0.6176\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 980us/step - loss: 0.6147\n",
      "EPISODE 94\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6125\n",
      "EPISODE 95\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6097\n",
      "EPISODE 96\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 846us/step - loss: 0.6075\n",
      "EPISODE 97\n",
      "TRAINING\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6194\n"
     ]
    }
   ],
   "source": [
    "agent = Agent()\n",
    "agent.run_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.9470717 ,  1.0848715 ,  0.90001225],\n",
       "        [-0.355273  ,  0.97696346, -0.00558327]], dtype=float32),\n",
       " array([ 0.        ,  0.12024263, -0.10834593], dtype=float32),\n",
       " array([[-0.05456865,  0.6267977 ,  0.15340126, -0.0262621 ],\n",
       "        [ 0.7338221 ,  0.4332879 ,  0.70204073,  0.3178726 ],\n",
       "        [-0.11937756,  0.7750663 , -0.4944009 ,  0.12508443]],\n",
       "       dtype=float32),\n",
       " array([ 0.10908177, -0.09804757,  0.11643344,  0.11921539], dtype=float32)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.357169  4.808519  6.768729  3.3899775]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[6.649575  3.7638104 6.3736625 2.9523869]\n",
      "(0, 9) 0\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "env_test = Environment()\n",
    "env_test.current_point_x = 1\n",
    "env_test.current_point_y = 9\n",
    "state = (env_test.current_point_x, env_test.current_point_y)\n",
    "            \n",
    "for j in range(100):\n",
    "    x = state[0]\n",
    "    y = state[1]\n",
    "    inputs = np.array([x, y]).reshape((1, 2))\n",
    "    move_prediction = np.array(agent.model.predict(inputs)[0])\n",
    "    print(move_prediction)\n",
    "    prediction_action = np.argmax(move_prediction)\n",
    "    env_test.move(prediction_action)\n",
    "    state = (env_test.current_point_x, env_test.current_point_y)\n",
    "    print(state, prediction_action)\n",
    "    env_test.maze[env_test.current_point_y, env_test.current_point_x] = 1\n",
    "    done = env_test.is_done()\n",
    "    if done:\n",
    "        print(\"DONE\")\n",
    "        break\n",
    "print(env_test.maze)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
